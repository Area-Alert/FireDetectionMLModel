{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1201 01:13:07.375697 15940 deprecation_wrapper.py:119] From c:\\users\\andrew\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "c:\\users\\andrew\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n",
      "W1201 01:13:07.419461 15940 deprecation_wrapper.py:119] From c:\\users\\andrew\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1201 01:13:07.426724 15940 deprecation_wrapper.py:119] From c:\\users\\andrew\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1201 01:13:07.474595 15940 deprecation_wrapper.py:119] From c:\\users\\andrew\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "c:\\users\\andrew\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "W1201 01:13:07.590041 15940 deprecation_wrapper.py:119] From c:\\users\\andrew\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1201 01:13:07.633918 15940 deprecation_wrapper.py:119] From c:\\users\\andrew\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1201 01:13:07.647659 15940 deprecation.py:323] From c:\\users\\andrew\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 649 images belonging to 2 classes.\n",
      "Found 76 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\andrew\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\andrew\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=100, epochs=15, validation_data=<keras_pre..., use_multiprocessing=False, workers=8, validation_steps=500)`\n",
      "W1201 01:13:08.393686 15940 deprecation_wrapper.py:119] From c:\\users\\andrew\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 [==============================] - 64s 643ms/step - loss: 0.3544 - acc: 0.8298 - val_loss: 0.4478 - val_acc: 0.7894\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 0.1688 - acc: 0.9328 - val_loss: 0.1220 - val_acc: 0.9736\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 37s 374ms/step - loss: 0.1255 - acc: 0.9467 - val_loss: 0.3543 - val_acc: 0.8683\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 44s 437ms/step - loss: 0.1072 - acc: 0.9579 - val_loss: 0.2359 - val_acc: 0.8815\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 38s 382ms/step - loss: 0.0852 - acc: 0.9755 - val_loss: 0.2755 - val_acc: 0.8684\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 40s 399ms/step - loss: 0.0513 - acc: 0.9825 - val_loss: 0.3858 - val_acc: 0.8553\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - 40s 399ms/step - loss: 0.0522 - acc: 0.9823 - val_loss: 0.4942 - val_acc: 0.8157\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - 42s 417ms/step - loss: 0.0491 - acc: 0.9823 - val_loss: 0.2936 - val_acc: 0.8686\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 0.0301 - acc: 0.9898 - val_loss: 0.2872 - val_acc: 0.9079\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - 47s 472ms/step - loss: 0.0257 - acc: 0.9919 - val_loss: 0.1705 - val_acc: 0.9211\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 0.0240 - acc: 0.9917 - val_loss: 0.5160 - val_acc: 0.8553\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 43s 430ms/step - loss: 0.0186 - acc: 0.9934 - val_loss: 0.2684 - val_acc: 0.8815\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 45s 454ms/step - loss: 0.0079 - acc: 0.9975 - val_loss: 0.4098 - val_acc: 0.8684\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 0.0288 - acc: 0.9903 - val_loss: 0.2052 - val_acc: 0.9079\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 48s 484ms/step - loss: 0.0174 - acc: 0.9936 - val_loss: 0.3927 - val_acc: 0.8684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aee4a3e748>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "classifier=Sequential()\n",
    "#convolution\n",
    "classifier.add(Convolution2D(32,3,3,input_shape=(64,64,3),activation='relu'))\n",
    "#max pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Convolution2D(32,3,3,activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Flattening\n",
    "\n",
    "\n",
    "classifier.add(Flatten())\n",
    "#Hidden and output layers\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=1,activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam',loss= 'binary_crossentropy',metrics=['accuracy'])\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "        'dataset\\\\train_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset\\\\test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "from PIL import Image\n",
    "classifier.fit_generator(\n",
    "        train_set,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=15,\n",
    "        validation_data=test_set,\n",
    "        nb_val_samples=500,\n",
    "        use_multiprocessing=False,\n",
    "        workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[0]\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset//single_prediction//1200px-Good_Food_Display_-_NCI_Visuals_Online.jpg', target_size=(64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = classifier.predict(test_image)\n",
    "luna = classifier.predict_proba(test_image)\n",
    "if result[0][0] == 1:\n",
    "    print(\"Not Fire\")\n",
    "else:\n",
    "    print(\"Fire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(luna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset//single_prediction//A-Alamy-BXWK5E_vvmkuf.jpg', target_size=(64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = classifier.predict(test_image)\n",
    "luna = classifier.predict_proba(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(luna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset//single_prediction//smoke-fire-sam.jpg', target_size=(64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = classifier.predict(test_image)\n",
    "luna = classifier.predict_proba(test_image)\n",
    "print(result)\n",
    "print(luna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset//single_prediction//newpic.jpg', target_size=(64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = classifier.predict(test_image)\n",
    "luna = classifier.predict_proba(test_image)\n",
    "print(result)\n",
    "print(luna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset//single_prediction//foods-that-lower-cholesterol-1296x728-feature.jpg', target_size=(64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = classifier.predict(test_image)\n",
    "luna = classifier.predict_proba(test_image)\n",
    "print(result)\n",
    "print(luna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
